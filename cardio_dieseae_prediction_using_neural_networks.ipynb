{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433834</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443711</td>\n",
       "      <td>-0.845741</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.309613</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>0.759448</td>\n",
       "      <td>0.771644</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.245845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>-0.706160</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745799</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>1.335923</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.806166</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.485474</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.992694</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.628408</td>\n",
       "      <td>-0.496787</td>\n",
       "      <td>-0.356915</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.073318</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897072</td>\n",
       "      <td>1.317775</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.662604</td>\n",
       "      <td>1.457357</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.727567</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.775183</td>\n",
       "      <td>-0.217624</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>-0.426996</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0 -0.433834       2  0.443711 -0.845741 -0.921194 -0.134931            1   \n",
       "1  0.309613       1 -1.018961  0.759448  0.771644  0.877460            3   \n",
       "2 -0.245845       1  0.078043 -0.706160  0.207365 -1.147322            3   \n",
       "3 -0.745799       2  0.565600  0.550076  1.335923  1.889851            1   \n",
       "4 -0.806166       1 -1.018961 -1.264486 -1.485474 -2.159713            1   \n",
       "5  0.992694       1 -1.628408 -0.496787 -0.356915 -0.134931            2   \n",
       "6  1.073318       1 -0.897072  1.317775  0.207365 -0.134931            3   \n",
       "7  1.264143       2  1.662604  1.457357  0.207365  0.877460            3   \n",
       "8 -0.727567       1 -0.775183 -0.217624 -0.921194 -1.147322            1   \n",
       "9  0.149985       1 -0.043847 -0.426996 -0.921194 -2.159713            1   \n",
       "\n",
       "   gluc  smoke  active  cardio  \n",
       "0     1      0       1       0  \n",
       "1     1      0       1       1  \n",
       "2     1      0       0       1  \n",
       "3     1      0       1       1  \n",
       "4     1      0       0       0  \n",
       "5     2      0       0       0  \n",
       "6     1      0       1       0  \n",
       "7     3      0       1       1  \n",
       "8     1      0       1       0  \n",
       "9     1      0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the preprocessed data\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into trainning and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"cardio\"],axis=1)\n",
    "y = df[\"cardio\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the counts for training and test dataset\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,5))\n",
    "sns.countplot(data=df, x = y_train, ax = ax[0])\n",
    "ax[0].set_title(\"Train Set\")\n",
    "sns.countplot(data=df, x = y_test, ax = ax[1])\n",
    "ax[1].set_title(\"Test Set\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us find the neural network architecture for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Layer with fixed unit choices\n",
    "    model.add(Dense(hp.Choice('units', [128, 256, 512, 1024])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.05, 0.01, 0.001])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_recall',  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='One hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 00m 34s]\n",
      "val_recall: 0.7448691725730896\n",
      "\n",
      "Best val_recall So Far: 0.8189864754676819\n",
      "Total elapsed time: 00h 03m 44s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=15,  \n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    #callbacks=[early_stopping],  # Use Early Stopping\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best number of units in the first layer: 128\n",
      "Best activation function: relu\n",
      "Best dropout rate: 0.2\n",
      "Best optimizer: rmsprop\n",
      "Best learning rate: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best number of units in the first layer: {best_hps.get('units')}\n",
    "Best activation function: {best_hps.get('activation')}\n",
    "Best dropout rate: {best_hps.get('dropout')}\n",
    "Best optimizer: {best_hps.get('optimizer')}\n",
    "Best learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.6226 - recall_2: 0.6886 - val_loss: 0.5896 - val_recall_2: 0.6764\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5894 - recall_2: 0.6419 - val_loss: 0.5998 - val_recall_2: 0.6442\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5933 - recall_2: 0.6313 - val_loss: 0.5777 - val_recall_2: 0.6029\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5987 - recall_2: 0.6615 - val_loss: 0.5881 - val_recall_2: 0.7040\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5902 - recall_2: 0.6350 - val_loss: 0.5936 - val_recall_2: 0.5646\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5941 - recall_2: 0.6254 - val_loss: 0.6144 - val_recall_2: 0.3789\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5971 - recall_2: 0.6367 - val_loss: 0.6252 - val_recall_2: 0.5176\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5942 - recall_2: 0.6683 - val_loss: 0.6038 - val_recall_2: 0.7197\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5897 - recall_2: 0.6103 - val_loss: 0.6053 - val_recall_2: 0.8268\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5934 - recall_2: 0.6514 - val_loss: 0.5875 - val_recall_2: 0.6950\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5926 - recall_2: 0.6273 - val_loss: 0.5918 - val_recall_2: 0.5995\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5982 - recall_2: 0.6077 - val_loss: 0.5711 - val_recall_2: 0.6795\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5946 - recall_2: 0.6315 - val_loss: 0.5811 - val_recall_2: 0.6958\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5986 - recall_2: 0.6304 - val_loss: 0.5793 - val_recall_2: 0.6815\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5946 - recall_2: 0.6198 - val_loss: 0.5733 - val_recall_2: 0.6538\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5937 - recall_2: 0.6254 - val_loss: 0.5866 - val_recall_2: 0.6331\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5961 - recall_2: 0.6170 - val_loss: 0.5964 - val_recall_2: 0.5665\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5933 - recall_2: 0.6172 - val_loss: 0.6101 - val_recall_2: 0.4948\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.6002 - recall_2: 0.6118 - val_loss: 0.5996 - val_recall_2: 0.5517\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5990 - recall_2: 0.6127 - val_loss: 0.5783 - val_recall_2: 0.7404\n",
      "Test Recall: 0.7404\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7343</td>\n",
       "      <td>3076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2669</td>\n",
       "      <td>7612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         7343         3076\n",
       "Actual 1         2669         7612"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.25%\n",
      "Precision: 71.22%\n",
      "Recall: 74.04%\n",
      "F1_score: 72.60%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with two hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.005, 0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_recall',  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Two hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 01m 06s]\n",
      "val_recall: 0.7550821900367737\n",
      "\n",
      "Best val_recall So Far: 0.7665596604347229\n",
      "Total elapsed time: 00h 06m 54s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=15,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 128\n",
      "- Layer 1 Activation: relu\n",
      "- Layer 2 Dropout: 0.2\n",
      "- Layer 2 Units: 64\n",
      "- Layer 2 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.3\n",
      "- Optimizer: adam\n",
      "- Learning Rate: 0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5714 - recall_2: 0.6820 - val_loss: 0.5553 - val_recall_2: 0.7516\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5559 - recall_2: 0.7047 - val_loss: 0.5599 - val_recall_2: 0.7389\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.5508 - recall_2: 0.7030 - val_loss: 0.5538 - val_recall_2: 0.7151\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5571 - recall_2: 0.7019 - val_loss: 0.5503 - val_recall_2: 0.7219\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5521 - recall_2: 0.7143 - val_loss: 0.5595 - val_recall_2: 0.7428\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5534 - recall_2: 0.7144 - val_loss: 0.5571 - val_recall_2: 0.7484\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5558 - recall_2: 0.7149 - val_loss: 0.5514 - val_recall_2: 0.7343\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5523 - recall_2: 0.7189 - val_loss: 0.5519 - val_recall_2: 0.6942\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5502 - recall_2: 0.7120 - val_loss: 0.5540 - val_recall_2: 0.6986\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5479 - recall_2: 0.7254 - val_loss: 0.5537 - val_recall_2: 0.7085\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5515 - recall_2: 0.7164 - val_loss: 0.5499 - val_recall_2: 0.7061\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5512 - recall_2: 0.7200 - val_loss: 0.5505 - val_recall_2: 0.6994\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5530 - recall_2: 0.7199 - val_loss: 0.5492 - val_recall_2: 0.7106\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5507 - recall_2: 0.7108 - val_loss: 0.5524 - val_recall_2: 0.7456\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5483 - recall_2: 0.7234 - val_loss: 0.5534 - val_recall_2: 0.7535\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5475 - recall_2: 0.7293 - val_loss: 0.5541 - val_recall_2: 0.6919\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5516 - recall_2: 0.7172 - val_loss: 0.5503 - val_recall_2: 0.7199\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5515 - recall_2: 0.7206 - val_loss: 0.5526 - val_recall_2: 0.7119\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5472 - recall_2: 0.7160 - val_loss: 0.5528 - val_recall_2: 0.7129\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5502 - recall_2: 0.7172 - val_loss: 0.5511 - val_recall_2: 0.7228\n",
      "Test Recall: 0.7228\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7642</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2850</td>\n",
       "      <td>7431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         7642         2777\n",
       "Actual 1         2850         7431"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.82%\n",
      "Precision: 72.80%\n",
      "Recall: 72.28%\n",
      "F1_score: 72.54%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with three hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.2, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    model.add(Dense(hp.Choice('units_3', [32, 64])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_3', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_3', values=[0.1, 0.2, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.005, 0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_recall',  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Three hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 01m 04s]\n",
      "val_recall: 0.7593619227409363\n",
      "\n",
      "Best val_recall So Far: 0.7868884205818176\n",
      "Total elapsed time: 00h 06m 50s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=15,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 128\n",
      "- Layer 1 Activation: relu\n",
      "- Layer 2 Dropout: 0.2\n",
      "- Layer 2 Units: 64\n",
      "- Layer 2 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.3\n",
      "- Layer 3 Units: 32\n",
      "- Layer 3 Activation: leaky_relu\n",
      "- Layer 3 Dropout: 0.2\n",
      "- Optimizer: adam\n",
      "- Learning Rate: 0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Layer 3 Units: {best_hps.get('units_3')}\n",
    "- Layer 3 Activation: {best_hps.get(f'activation_3')}\n",
    "- Layer 3 Dropout: {best_hps.get('dropout_3')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5771 - recall_2: 0.6827 - val_loss: 0.5572 - val_recall_2: 0.6611\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5569 - recall_2: 0.6983 - val_loss: 0.5664 - val_recall_2: 0.6361\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5597 - recall_2: 0.6909 - val_loss: 0.5604 - val_recall_2: 0.7162\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5570 - recall_2: 0.7071 - val_loss: 0.5545 - val_recall_2: 0.7295\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5596 - recall_2: 0.6968 - val_loss: 0.5566 - val_recall_2: 0.7137\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5562 - recall_2: 0.6874 - val_loss: 0.5518 - val_recall_2: 0.7090\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5524 - recall_2: 0.7024 - val_loss: 0.5582 - val_recall_2: 0.6760\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5546 - recall_2: 0.7024 - val_loss: 0.5492 - val_recall_2: 0.7080\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5547 - recall_2: 0.6998 - val_loss: 0.5516 - val_recall_2: 0.7056\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5551 - recall_2: 0.7115 - val_loss: 0.5498 - val_recall_2: 0.6883\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5568 - recall_2: 0.6929 - val_loss: 0.5530 - val_recall_2: 0.6968\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5521 - recall_2: 0.7163 - val_loss: 0.5550 - val_recall_2: 0.6965\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5563 - recall_2: 0.7096 - val_loss: 0.5502 - val_recall_2: 0.6877\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5497 - recall_2: 0.7078 - val_loss: 0.5574 - val_recall_2: 0.7012\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5537 - recall_2: 0.7080 - val_loss: 0.5525 - val_recall_2: 0.7386\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5544 - recall_2: 0.7083 - val_loss: 0.5619 - val_recall_2: 0.6330\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5559 - recall_2: 0.7066 - val_loss: 0.5506 - val_recall_2: 0.6859\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5518 - recall_2: 0.7000 - val_loss: 0.5529 - val_recall_2: 0.6933\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5523 - recall_2: 0.7146 - val_loss: 0.5517 - val_recall_2: 0.6928\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5538 - recall_2: 0.7124 - val_loss: 0.5522 - val_recall_2: 0.7434\n",
      "Test Recall: 0.7434\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7382</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>2638</td>\n",
       "      <td>7643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         7382         3037\n",
       "Actual 1         2638         7643"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.58%\n",
      "Precision: 71.56%\n",
      "Recall: 74.34%\n",
      "F1_score: 72.93%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
