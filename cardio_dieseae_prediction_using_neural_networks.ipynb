{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.433834</td>\n",
       "      <td>2</td>\n",
       "      <td>0.443711</td>\n",
       "      <td>-0.845741</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.309613</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>0.759448</td>\n",
       "      <td>0.771644</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.245845</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>-0.706160</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745799</td>\n",
       "      <td>2</td>\n",
       "      <td>0.565600</td>\n",
       "      <td>0.550076</td>\n",
       "      <td>1.335923</td>\n",
       "      <td>1.889851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.806166</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.018961</td>\n",
       "      <td>-1.264486</td>\n",
       "      <td>-1.485474</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.992694</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.628408</td>\n",
       "      <td>-0.496787</td>\n",
       "      <td>-0.356915</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.073318</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.897072</td>\n",
       "      <td>1.317775</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>-0.134931</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264143</td>\n",
       "      <td>2</td>\n",
       "      <td>1.662604</td>\n",
       "      <td>1.457357</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>0.877460</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.727567</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.775183</td>\n",
       "      <td>-0.217624</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-1.147322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.149985</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.043847</td>\n",
       "      <td>-0.426996</td>\n",
       "      <td>-0.921194</td>\n",
       "      <td>-2.159713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  gender    height    weight     ap_hi     ap_lo  cholesterol  \\\n",
       "0 -0.433834       2  0.443711 -0.845741 -0.921194 -0.134931            1   \n",
       "1  0.309613       1 -1.018961  0.759448  0.771644  0.877460            3   \n",
       "2 -0.245845       1  0.078043 -0.706160  0.207365 -1.147322            3   \n",
       "3 -0.745799       2  0.565600  0.550076  1.335923  1.889851            1   \n",
       "4 -0.806166       1 -1.018961 -1.264486 -1.485474 -2.159713            1   \n",
       "5  0.992694       1 -1.628408 -0.496787 -0.356915 -0.134931            2   \n",
       "6  1.073318       1 -0.897072  1.317775  0.207365 -0.134931            3   \n",
       "7  1.264143       2  1.662604  1.457357  0.207365  0.877460            3   \n",
       "8 -0.727567       1 -0.775183 -0.217624 -0.921194 -1.147322            1   \n",
       "9  0.149985       1 -0.043847 -0.426996 -0.921194 -2.159713            1   \n",
       "\n",
       "   gluc  smoke  active  cardio  \n",
       "0     1      0       1       0  \n",
       "1     1      0       1       1  \n",
       "2     1      0       0       1  \n",
       "3     1      0       1       1  \n",
       "4     1      0       0       0  \n",
       "5     2      0       0       0  \n",
       "6     1      0       1       0  \n",
       "7     3      0       1       1  \n",
       "8     1      0       1       0  \n",
       "9     1      0       0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the preprocessed data\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into trainning and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"cardio\"],axis=1)\n",
    "y = df[\"cardio\"].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#looking at the counts for training and test dataset\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,5))\n",
    "sns.countplot(data=df, x = y_train, ax = ax[0])\n",
    "ax[0].set_title(\"Train Set\")\n",
    "sns.countplot(data=df, x = y_test, ax = ax[1])\n",
    "ax[1].set_title(\"Test Set\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us find the neural network architecture for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input Layer with fixed unit choices\n",
    "    model.add(Dense(hp.Choice('units', [128, 256, 512, 1024])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout', values=[0.1, 0.3])))  \n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_recall',  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='One hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 00m 33s]\n",
      "val_recall: 0.7161632180213928\n",
      "\n",
      "Best val_recall So Far: 0.7544134855270386\n",
      "Total elapsed time: 00h 03m 51s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(\n",
    "    X_train, y_train, \n",
    "    epochs=15,  \n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    #callbacks=[early_stopping],  # Use Early Stopping\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best number of units in the first layer: 1024\n",
      "Best activation function: leaky_relu\n",
      "Best dropout rate: 0.3\n",
      "Best optimizer: rmsprop\n",
      "Best learning rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best number of units in the first layer: {best_hps.get('units')}\n",
    "Best activation function: {best_hps.get('activation')}\n",
    "Best dropout rate: {best_hps.get('dropout')}\n",
    "Best optimizer: {best_hps.get('optimizer')}\n",
    "Best learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.5625 - recall_2: 0.6978 - val_loss: 0.5612 - val_recall_2: 0.7348\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5544 - recall_2: 0.6941 - val_loss: 0.5533 - val_recall_2: 0.6969\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5504 - recall_2: 0.6978 - val_loss: 0.5511 - val_recall_2: 0.7138\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5461 - recall_2: 0.6967 - val_loss: 0.5513 - val_recall_2: 0.7314\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5494 - recall_2: 0.6997 - val_loss: 0.5503 - val_recall_2: 0.6811\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5494 - recall_2: 0.6953 - val_loss: 0.5502 - val_recall_2: 0.6717\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5484 - recall_2: 0.6924 - val_loss: 0.5566 - val_recall_2: 0.6301\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5533 - recall_2: 0.6912 - val_loss: 0.5498 - val_recall_2: 0.6869\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5441 - recall_2: 0.7054 - val_loss: 0.5524 - val_recall_2: 0.6658\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5465 - recall_2: 0.6944 - val_loss: 0.5512 - val_recall_2: 0.7019\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.5454 - recall_2: 0.7006 - val_loss: 0.5494 - val_recall_2: 0.7243\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.5498 - recall_2: 0.6933 - val_loss: 0.5515 - val_recall_2: 0.7077\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.5487 - recall_2: 0.7003 - val_loss: 0.5500 - val_recall_2: 0.6944\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.5489 - recall_2: 0.6974 - val_loss: 0.5498 - val_recall_2: 0.6904\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.5499 - recall_2: 0.6975 - val_loss: 0.5483 - val_recall_2: 0.6921\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.5466 - recall_2: 0.6957 - val_loss: 0.5509 - val_recall_2: 0.6761\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5483 - recall_2: 0.6992 - val_loss: 0.5500 - val_recall_2: 0.7152\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5483 - recall_2: 0.6987 - val_loss: 0.5524 - val_recall_2: 0.6897\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5485 - recall_2: 0.6959 - val_loss: 0.5498 - val_recall_2: 0.7005\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.5453 - recall_2: 0.6972 - val_loss: 0.5545 - val_recall_2: 0.6558\n",
      "Test Recall: 0.6558\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8474</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3509</td>\n",
       "      <td>6687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         8474         2030\n",
       "Actual 1         3509         6687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.24%\n",
      "Precision: 76.71%\n",
      "Recall: 65.58%\n",
      "F1_score: 70.71%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for Keras Tuner with reduced search space\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Choice('units_1', [128,256])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_1', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_1', values=[0.1, 0.3])))  \n",
    "\n",
    "    model.add(Dense(hp.Choice('units_2', [64,128])))\n",
    "\n",
    "    # Activation function selection\n",
    "    activation_choice = hp.Choice('activation_2', ['relu', 'leaky_relu'])\n",
    "    if activation_choice == 'relu':\n",
    "        model.add(ReLU())\n",
    "    else:\n",
    "        model.add(LeakyReLU(negative_slope=0.01))  # Default Leaky ReLU alpha=0.01\n",
    "\n",
    "    # Dropout Layer with tunable choice\n",
    "    model.add(Dropout(hp.Choice('dropout_2', values=[0.1, 0.3])))\n",
    "\n",
    "    # Output layer (Binary classification)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer selection\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.0005])  # Added another value for tuning\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Keras Tuner with Hyperband, lowering max_epochs to 20 and factor to 3\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_recall',  # Optimize for recall\n",
    "    max_epochs=15,           # Reduced maximum epochs\n",
    "    factor=4,\n",
    "    directory='Two hidden layer',\n",
    "    project_name='disease_classification_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 Complete [00h 02m 34s]\n",
      "val_recall: 0.7561789155006409\n",
      "\n",
      "Best val_recall So Far: 0.7561789155006409\n",
      "Total elapsed time: 00h 09m 28s\n"
     ]
    }
   ],
   "source": [
    "# # Define Early Stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_recall',  # Stop training if recall doesn't improve\n",
    "#     patience=4,            # Wait for 4 epochs before stopping\n",
    "#     restore_best_weights=True  # Restore best model\n",
    "# )\n",
    "\n",
    "# Perform hyperparameter search using a fixed batch size (e.g., 32) during the search phase with verbose off\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=15,  # Reduced number of epochs\n",
    "             validation_data=(X_test, y_test),\n",
    "             batch_size=32,\n",
    "             #callbacks=[early_stopping],  # Use Early Stopping\n",
    "             verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters:\n",
      "- Layer 1 Units: 256\n",
      "- Layer 1 Activation: relu\n",
      "- Layer 2 Dropout: 0.3\n",
      "- Layer 2 Units: 128\n",
      "- Layer 2 Activation: leaky_relu\n",
      "- Layer 2 Dropout: 0.1\n",
      "- Optimizer: adam\n",
      "- Learning Rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Layer 1 Units: {best_hps.get('units_1')}\n",
    "- Layer 1 Activation: {best_hps.get('activation_1')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_1')}\n",
    "- Layer 2 Units: {best_hps.get('units_2')}\n",
    "- Layer 2 Activation: {best_hps.get(f'activation_2')}\n",
    "- Layer 2 Dropout: {best_hps.get('dropout_2')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.5679 - recall_2: 0.6955 - val_loss: 0.5510 - val_recall_2: 0.6760\n",
      "Epoch 2/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.5516 - recall_2: 0.6914 - val_loss: 0.5488 - val_recall_2: 0.7031\n",
      "Epoch 3/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.5457 - recall_2: 0.7078 - val_loss: 0.5471 - val_recall_2: 0.6664\n",
      "Epoch 4/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.5502 - recall_2: 0.6999 - val_loss: 0.5462 - val_recall_2: 0.6663\n",
      "Epoch 5/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.5463 - recall_2: 0.6868 - val_loss: 0.5468 - val_recall_2: 0.7299\n",
      "Epoch 6/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.5459 - recall_2: 0.7010 - val_loss: 0.5477 - val_recall_2: 0.7298\n",
      "Epoch 7/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.5463 - recall_2: 0.6942 - val_loss: 0.5465 - val_recall_2: 0.7016\n",
      "Epoch 8/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.5457 - recall_2: 0.6937 - val_loss: 0.5446 - val_recall_2: 0.6943\n",
      "Epoch 9/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.5478 - recall_2: 0.6896 - val_loss: 0.5459 - val_recall_2: 0.7193\n",
      "Epoch 10/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.5447 - recall_2: 0.6965 - val_loss: 0.5459 - val_recall_2: 0.6999\n",
      "Epoch 11/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5406 - recall_2: 0.7001 - val_loss: 0.5450 - val_recall_2: 0.7032\n",
      "Epoch 12/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5438 - recall_2: 0.6918 - val_loss: 0.5455 - val_recall_2: 0.7206\n",
      "Epoch 13/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5427 - recall_2: 0.6949 - val_loss: 0.5446 - val_recall_2: 0.7113\n",
      "Epoch 14/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5408 - recall_2: 0.7008 - val_loss: 0.5449 - val_recall_2: 0.7028\n",
      "Epoch 15/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5406 - recall_2: 0.7072 - val_loss: 0.5455 - val_recall_2: 0.7030\n",
      "Epoch 16/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.5414 - recall_2: 0.7017 - val_loss: 0.5447 - val_recall_2: 0.7039\n",
      "Epoch 17/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5433 - recall_2: 0.6964 - val_loss: 0.5464 - val_recall_2: 0.7168\n",
      "Epoch 18/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5462 - recall_2: 0.6943 - val_loss: 0.5465 - val_recall_2: 0.6933\n",
      "Epoch 19/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5433 - recall_2: 0.6986 - val_loss: 0.5456 - val_recall_2: 0.6996\n",
      "Epoch 20/20\n",
      "\u001b[1m1510/1510\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.5411 - recall_2: 0.6998 - val_loss: 0.5451 - val_recall_2: 0.6975\n",
      "Test Recall: 0.6975\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model using the best batch size from hyperparameters with verbose off\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), \n",
    "                         batch_size=32,\n",
    "                         verbose=1)\n",
    "\n",
    "# Evaluate on the test set with verbose off\n",
    "loss, recall = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test,verbose=0)\n",
    "y_pred_classes = (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8077</td>\n",
       "      <td>2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3084</td>\n",
       "      <td>7112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         8077         2427\n",
       "Actual 1         3084         7112"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_matrix = confusion_matrix(y_test, y_pred_classes)\n",
    "con_matrix = pd.DataFrame(data = con_matrix, columns= [\"Predicted 0\",\"Predicted 1\"], index= [\"Actual 0\", \"Actual 1\"])\n",
    "con_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.38%\n",
      "Precision: 74.56%\n",
      "Recall: 69.75%\n",
      "F1_score: 72.07%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_classes) *100\n",
    "precision = precision_score(y_test, y_pred_classes) *100\n",
    "recall = recall_score(y_test, y_pred_classes) *100\n",
    "f1 = f1_score(y_test,y_pred_classes) *100\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "print(f\"F1_score: {f1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
